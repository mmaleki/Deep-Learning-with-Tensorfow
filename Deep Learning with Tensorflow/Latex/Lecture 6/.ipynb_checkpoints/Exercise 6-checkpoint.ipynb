{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1/(1+np.exp(-z)))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagation(b,X_hat,y_hat):\n",
    "    N=X_hat.shape[0]\n",
    "    z=np.dot(X_hat,b)\n",
    "    s=sigmoid(z)\n",
    "    temp=-(y_hat*np.log(s+0.001)+(1-y_hat)*np.log(1-s+0.001))\n",
    "    L= np.mean(temp,axis=0,keepdims=True)\n",
    "    x1=sigmoid(z)-y_hat\n",
    "    dL= 1/N*np.dot(x1.T,X_hat)\n",
    "    propagate={\"L\":L,\"dL\":dL}\n",
    "    return propagate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "\n",
    "+ In this section you need to update weight b by gradient descent based on the training data X_hat and y_hat.\n",
    "+ In his pice of code, dl is the derivative of loss with respect to weight matrix b.\n",
    "+ Fill None parts in the code.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(b,X_hat,y_hat,eta):\n",
    "    dl=propagation(b,X_hat,y_hat)[\"dL\"].T\n",
    "    update=None\n",
    "    return update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(m,n,method):\n",
    "    if method=='zero':\n",
    "        b=np.zeros((m,n))\n",
    "    elif method=='random':\n",
    "        b=np.random.randn(m,n)\n",
    "    else:\n",
    "        raise Exception('Choose correct method: zero or random')\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_opt(X_hat,y_hat,eta,steps,initialization):\n",
    "    N=X_hat.shape[0]\n",
    "    p=X_hat.shape[1]\n",
    "    b=init(p,1,initialization)\n",
    "    for i in range(steps):       \n",
    "        b1=update(b,X_hat,y_hat,eta)\n",
    "        b=update(b1,X_hat,y_hat,eta)\n",
    "        loss=propagation(b,X_hat,y_hat)[\"L\"]\n",
    "        if i%10 == 0:\n",
    "            print (\"Loss after iteration %i= %f\" %(i, loss))\n",
    "            \n",
    "    return b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "+ In this section based on the probability of the output in the binary classifier algorithm, complete the code by filling the None parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,X_hat,y_hat,eta,steps=20):\n",
    "    b_optimal=b_opt(X_hat,y_hat,eta,steps,'random')\n",
    "    z=np.dot(x.T,b_optimal)\n",
    "    prob=sigmoid(z)\n",
    "    if None:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(x,X_train,y_train,eta,steps,initialization):\n",
    "    N=X_train.shape[0]\n",
    "    one=np.ones((N,1))\n",
    "    X_hat=np.concatenate((one,X_train),axis=1)\n",
    "    b_optimal=b_opt(X_hat,y_train,eta,steps,initialization)\n",
    "    xnew=np.append(1,x).reshape(-1,1)\n",
    "    z=np.dot(xnew.T,b_optimal)\n",
    "    prob=sigmoid(z)\n",
    "    if None:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Data for Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_data(n_sample,shape_type):\n",
    "    ratio=2*np.pi/n_sample\n",
    "    t=np.arange(0,2*np.pi,ratio)\n",
    "    \n",
    "    if shape_type=='circle':\n",
    "        noise=np.random.randn(t.shape[0])/8\n",
    "        x1=np.sin(t)\n",
    "        y1=np.cos(t)+noise\n",
    "        noise2=np.random.randn(t.shape[0])/8\n",
    "        x2=1.5*np.sin(t)\n",
    "        y2=1.5*np.cos(t)+noise2\n",
    "    elif shape_type=='wave':\n",
    "        noise=np.random.randn(t.shape[0])/2\n",
    "        x1=t\n",
    "        y1=np.cos(2*t)+noise\n",
    "        noise2=np.random.randn(t.shape[0])/2\n",
    "        x2=t\n",
    "        y2=1.5*np.cos(2*t)+2+noise2\n",
    "    elif shape_type=='linear':\n",
    "        noise=np.random.randn(t.shape[0])\n",
    "        x1=t\n",
    "        y1=t+noise\n",
    "        noise2=np.random.randn(t.shape[0])\n",
    "        x2=t\n",
    "        y2=t+3+noise2\n",
    "    elif shape_type=='cluster':\n",
    "        noise=np.random.randn(t.shape[0])/3\n",
    "        x1=noise*np.cos(t)\n",
    "        y1=noise*np.sin(t)+noise\n",
    "        noise2=np.random.randn(t.shape[0])/3\n",
    "        x2=noise2*np.cos(t)+1\n",
    "        y2=noise2*np.sin(t)+1.5+noise2\n",
    "    elif shape_type=='lorenz':\n",
    "        rot=(lambda theta:np.array([[np.cos(theta), -np.sin(theta)],[np.sin(theta), np.cos(theta)]]) )\n",
    "        noise=np.random.randn(t.shape[0])/4\n",
    "        x01=noise*np.cos(t)\n",
    "        y01=3*noise*np.sin(t)\n",
    "        xy0=np.array([[x01,y01]]).T\n",
    "        xy=np.dot(rot(np.pi/4),xy0)\n",
    "        x1=xy[0,:,:]\n",
    "        y1=xy[1,:,:]\n",
    "        noise2=np.random.randn(t.shape[0])/4\n",
    "        x02=noise2*np.cos(t)+1\n",
    "        y02=3*noise2*np.sin(t)+1.5\n",
    "        xy02=np.array([[x02,y02]]).T\n",
    "        xy2=np.dot(rot(-np.pi/4),xy02)\n",
    "        x2=xy2[0,:,:]\n",
    "        y2=xy2[1,:,:]\n",
    "    else:\n",
    "        raise Exception('Insert true shape name: circle or crescent or linear or wave or cluster or lorenz')\n",
    "            \n",
    "    xy_red=np.column_stack((x1,y1))\n",
    "    l_red=np.ones((xy_red.shape[0],1)).astype(int)\n",
    "    red=np.column_stack((xy_red,l_red))\n",
    "    xy2_red=np.column_stack((x2,y2))\n",
    "    l_blue=np.zeros((xy2_red.shape[0],1)).astype(int)\n",
    "    blue=np.column_stack((xy2_red,l_blue))\n",
    "    total=np.concatenate([red,blue])\n",
    "    X=total[:,:2]\n",
    "    y=[item[0] for item in total[:,2:]]\n",
    "    y=np.array(y).astype(int)\n",
    "    \n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X,y):\n",
    "    df = pd.DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "    colors = {1:'red', 0:'blue'}\n",
    "    fig, ax = plt.subplots()\n",
    "    grouped = df.groupby('label')\n",
    "    for key, group in grouped:\n",
    "        group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X,y,ratio):\n",
    "    total=np.column_stack((X,y))\n",
    "    np.random.shuffle(total)\n",
    "    M=int(X.shape[0]*ratio)\n",
    "    X=total[:,:2]\n",
    "    y=total[:,2]\n",
    "    y=y.reshape(-1,1)\n",
    "    train_X, test_X=X[:M], X[M:]\n",
    "    train_y, test_y=y[:M], y[M:]\n",
    "    return train_X, test_X, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X,y,ratio,filename):\n",
    "    train_X, test_X, train_y, test_y=split(X,y,ratio)\n",
    "    one=np.ones((train_X.shape[0],1))\n",
    "    xhat=np.column_stack([one, train_X])\n",
    "    yhat=train_y\n",
    "    yhat=yhat.reshape(-1,1)\n",
    "    w=b_opt(xhat,yhat,0.5,10,'random')\n",
    "    x1=np.arange(np.min(X[:,0]),np.max(X[:,0]),0.01)\n",
    "    x2=-w[1]/w[2]*x1-w[0]/w[2]\n",
    "    y.reshape(-1,)\n",
    "    df = pd.DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "    colors = {1:'red', 0:'blue'}\n",
    "    fig, ax = plt.subplots()\n",
    "    grouped = df.groupby('label')\n",
    "    for key, group in grouped:\n",
    "        group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "    plt.plot(x1,x2,'go-')\n",
    "    plt.savefig(filename,dpi=400)\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1=making_data(500,'linear')\n",
    "X2, y2=making_data(500,'cluster')\n",
    "X3, y3=making_data(500,'circle')\n",
    "X4, y4=making_data(500,'wave')\n",
    "X5, y5=making_data(500,'lorenz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(X1,y1,0.8,\"HD1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "+ Plot decision boundary for (X2,y2) with learning rate=0.01\n",
    "+ Plot decision boundary for (X3,y3) with learning rate=0.1\n",
    "+ Plot decision boundary for (X4,y4) with learning rate=0.5\n",
    "+ Plot decision boundary for (X5,y5) with learning rate=0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4\n",
    "+ We have seen that any term of the loss function in the binary classifier is $\\mathcal{L}(w_1,w_2)=-\\hat{y}^{(i)}log(\\sigma(z^{(i)}))-(1-\\hat{y}^{(i)})log(1-\\sigma(z^{(i)}))$ where $z^{(i)}=w_1x_1^{(i)}+w_2x_2^{(i)}$. Compute the following partial derivatives of $\\mathcal{L}$ with respect to $w_1$ and $w_2$, i.e.,\n",
    "+ $$\\frac{\\partial \\mathcal{L}}{\\partial w_1}=?$$\n",
    "+ $$\\frac{\\partial \\mathcal{L}}{\\partial w_2}=?$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
